{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0bc6c1",
   "metadata": {},
   "source": [
    "### 1. Imports and Setup\n",
    "Import necessary libraries such as PyTorch, torchvision, and any other dependencies used for data handling, transformations, and model training.\n",
    "\n",
    "**Description**: This section loads all required modules and libraries needed for setting up data transformations, model creation, and training processes."
   ]
  },
  {
   "cell_type": "code",
   "id": "919c72e2ddce27a9",
   "metadata": {},
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "def imshow(img, label, prediction=None):\n",
    "    img = img.numpy().transpose((1, 2, 0))  # Rearrange to H x W x C\n",
    "    img = np.clip(img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]), 0, 1)  # De-normalize\n",
    "    plt.imshow(img)\n",
    "    if prediction is not None:\n",
    "        plt.title(f\"True Label: {label * 10}-{label * 10 + 10}\\nPredicted Label: {prediction * 10}-{prediction * 10 + 10}\")\n",
    "    else:\n",
    "        plt.title(f\"Label: {label * 10}-{label * 10 + 10}\")    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d0604fbba59f9b4",
   "metadata": {},
   "source": [
    "## Hyperparamters \n",
    "## We will use the following hyperparameters for training the model:\n",
    "- Batch size: 512\n",
    "- Learning rate: 0.01\n",
    "- Number of epochs: 1000 \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    " We don’t have data for certain ages (e.g no image of a 94 year old person), so we can group ages into ranges (like 90–95, 95–100) instead of predicting each specific age. \n",
    "This is called class binning. By using age ranges, the model can handle missing data more effectively and make more accurate predictions, even with a smaller dataset. "
   ]
  },
  {
   "cell_type": "code",
   "id": "5b058e88b556611d",
   "metadata": {},
   "source": [
    "import math\n",
    "SIZE_OF_BIN = 10\n",
    "NUM_OF_CLASSES = math.ceil(116 / SIZE_OF_BIN)\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1000"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Dataset and DataLoader Setup\n",
    "**Custom Dataset Class**: Define a custom dataset class if required, to load data from a specific directory or dataset.\n",
    "\n",
    "**DataLoader Initialization**: Initialize DataLoaders for training and testing, setting batch size and shuffling options.\n",
    "\n",
    "**Description**: Here, we define the dataset and data loader. A custom dataset class helps load the data according to specific requirements, while DataLoader batches and prepares the data for the model during training and evaluation."
   ],
   "id": "d3e43c24"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "# coutainer of classes\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_path):\n",
    "        self.image_files = [os.path.join(images_path, f) for f in os.listdir(images_path) \n",
    "                            if os.path.isfile(os.path.join(images_path, f)) and f.lower().endswith('.jpg')]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize([256], transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop([224]),\n",
    "            \n",
    "            # Subtle augmentations because a person normally e.g does not stand on upside down\n",
    "            transforms.RandomHorizontalFlip(p=0.2),       # Small chance of flipping\n",
    "            transforms.RandomRotation(degrees=5),         # Small rotation range\n",
    "            # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Subtle color jitter\n",
    "            \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_files[idx]).convert(\"RGB\")\n",
    "        image.verify()\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        age = self.image_files[idx].split(\"\\\\\")[-1].split('_')[0]\n",
    "        return image, int(age) // SIZE_OF_BIN \n",
    "\n",
    "\n",
    "dataset = CustomDataset(r\"C:\\Users\\morit\\Downloads\\UTKface_inthewild-20241024T082001Z-001\\UTKface_inthewild\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for images, labels in train_loader:\n",
    "    for image, label in zip(images, labels):\n",
    "        imshow(image)\n",
    "        \n",
    "    break\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6588c434c753570b",
   "metadata": {},
   "source": [
    "<h1> Calculate Class Weights </h1>\n",
    "Since the calculation of class takes a long time, we will use the hardcoded output of the calculation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Due to the large imbalance of the dataset, we need to calculate the class weights to ensure that the model does not overfit to the majority class.\n",
    " \n",
    "We will use the inverse frequency of each class as the class weight. This will help the model to pay more attention to the minority classes."
   ],
   "id": "30630d077010ecb2"
  },
  {
   "cell_type": "code",
   "id": "9748bbcf8c9f8119",
   "metadata": {},
   "source": [
    "from torch import tensor\n",
    "class_weights_tensor = tensor([0.1378, 0.0637, 0.3042, 0.1891, 0.0946, 0.0966, 0.0550, 0.0298, 0.0220,\n",
    "        0.0058, 0.0007, 0.0006], dtype=torch.float)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b17c8369204ee0e7",
   "metadata": {},
   "source": [
    "# import torch\n",
    "# from collections import defaultdict\n",
    "# \n",
    "# # Step 1: Count occurrences of each class\n",
    "# class_counts = defaultdict(int)\n",
    "# \n",
    "# for _, labels in train_loader:\n",
    "#     for label in labels.numpy():\n",
    "#             \n",
    "#         class_counts[label] += 1\n",
    "# \n",
    "# # Step 2: Calculate class weights\n",
    "# total_samples = sum(class_counts.values())\n",
    "# \n",
    "# # Calculate weights: inverse frequency\n",
    "# class_weights = {cls: count/ total_samples for cls, count in class_counts.items()}\n",
    "# # Convert t a tensor for PyTorch\n",
    "# class_weights_tensor = torch.tensor([class_weights[i] for i in range(NUM_OF_CLASSES)], dtype=torch.float)\n",
    "# \n",
    "# print(\"Class weights:\", class_weights_tensor)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc55184d4babde6f",
   "metadata": {},
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# \n",
    "# all_labels = []\n",
    "# \n",
    "# for _, labels in dataloader:\n",
    "#     all_labels.extend(labels.numpy())  \n",
    "# \n",
    "# all_labels = np.array(all_labels)\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(all_labels, bins=range(int(all_labels.min()), int(all_labels.max()) + 2), edgecolor='black', alpha=0.7)\n",
    "# plt.title('Age Distribution in Dataset')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Model Definition\n",
    "**Define Neural Network Architecture**: Specify the layers, activation functions, and architecture of the neural network.\n",
    "\n",
    "**Description**: This section builds the neural network model. Layers and activation functions are structured to capture the underlying patterns in the input data for classification tasks."
   ],
   "id": "1292a5f8"
  },
  {
   "cell_type": "code",
   "id": "e911e0e6d1e758e3",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class highLevelNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(highLevelNN, self).__init__()\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.CNN(x)\n",
    "\n",
    "\n",
    "class lowLevelNN(nn.Module):\n",
    "    def __init__(self, num_out):\n",
    "        super(lowLevelNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc4 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc6 = nn.Linear(in_features=64, out_features=num_out)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=6, stride=3, padding=1)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=6, stride=3, padding=1)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc6(x)\n",
    "\n",
    "\n",
    "class AgeNN(nn.Module):\n",
    "    def __init__(self, num_age):\n",
    "        super(AgeNN, self).__init__()\n",
    "        self.CNN = highLevelNN()\n",
    "        self.ageNN = lowLevelNN(num_out=num_age)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN(x)\n",
    "        return self.ageNN(x)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchsummary import summary\n",
    "    print('Testing out Multi-Label NN')\n",
    "    mlNN = AgeNN(NUM_OF_CLASSES).to(device)\n",
    "    \n",
    "    summary(mlNN, input_size=(3, 224, 224))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Training Configuration\n",
    "**Loss Function and Optimizer**: Define the loss function (e.g., Cross-Entropy Loss for classification) and optimizer (e.g., Adam or SGD) to minimize the error during training.\n",
    "\n",
    "**Learning Rate Scheduler**: Configure any learning rate scheduler, such as StepLR, to adjust the learning rate at certain intervals.\n",
    "\n",
    "**Description**: This part of the code sets up the parameters for model training. The loss function calculates the error between predictions and actual labels, while the optimizer updates the model weights. The scheduler gradually reduces the learning rate as training progresses to stabilize convergence."
   ],
   "id": "63a7bea9"
  },
  {
   "cell_type": "code",
   "id": "e5a585add2fe4496",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train(trainloader, testloader, model, opt, scheduler, num_epoch, save_path):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    age_loss = nn.CrossEntropyLoss()\n",
    "    print(\"1\")\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "\n",
    "        loop = tqdm(enumerate(trainloader), total=len(trainloader), leave=False)\n",
    "        age_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "\n",
    "        for _, (X, y) in loop:\n",
    "\n",
    "            age = y.to(device).long()\n",
    "            X = X.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                pred = model(X)\n",
    "                loss = age_loss(pred, age)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            age_correct += (pred.argmax(1) == age).type(torch.float).sum().item()\n",
    "            total += age.size(0)\n",
    "\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{num_epoch}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        age_acc = age_correct / total\n",
    "        print(f'Epoch: {epoch+1}/{num_epoch}, Age Accuracy: {age_acc * 100:.2f}%')\n",
    "\n",
    "        torch.save(model.state_dict(), f\"{save_path}/model_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            evaluate(testloader, model, epoch + 1)\n",
    "            \n",
    "def evaluate(loader, model, epoch):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    good_images = []\n",
    "    bad_images = []\n",
    "    \n",
    "    for X_test, y_test in loader:\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device).long()\n",
    "        test_pred = model(X_test)\n",
    "        \n",
    "        preds = test_pred.argmax(1)\n",
    "\n",
    "        test_correct += (test_pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
    "        test_total += y_test.size(0)\n",
    "        \n",
    "        all_preds.extend(test_pred.argmax(1).cpu().numpy())\n",
    "        all_labels.extend(y_test.cpu().numpy())\n",
    "        for i in range(len(y_test)):\n",
    "            if preds[i] == y_test[i] and len(good_images) < 10:  # Correctly classified\n",
    "                good_images.append((X_test[i].cpu(), y_test[i].cpu()))\n",
    "            elif preds[i] != y_test[i] and len(bad_images) < 50:  # Incorrectly classified\n",
    "                bad_images.append((X_test[i].cpu(), y_test[i].cpu(), preds[i].cpu()))\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f'Test Accuracy after Epoch {epoch}: {test_acc * 100:.2f}%')\n",
    "    print(f'Test F1 Score after Epoch {epoch}: {f1 * 100:.2f}%')\n",
    "    print(f'Test Balanced Accuracy after Epoch {epoch}: {balanced_acc * 100:.2f}%\\n')\n",
    "    \n",
    "    print(\"Good Examples (Correctly Classified):\")\n",
    "    for img, label in good_images:\n",
    "        imshow(img, label)\n",
    "    \n",
    "    print(\"Bad Examples (Incorrectly Classified):\")\n",
    "    for img, label, pred in bad_images:\n",
    "        imshow(img, label, prediction=pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6eb9b2e3cc257fa6",
   "metadata": {},
   "source": [
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# # Decrease the learning rate by 0.1 every 10 epochs\n",
    "# import os   \n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "# model = AgeNN(NUM_OF_CLASSES)  \n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "# # Train the model\n",
    "# train(train_loader, test_loader, model, optimizer,scheduler, EPOCHS, \"model_weights\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 7. Evaluation and Testing\n",
    "**Test Model Performance**: Evaluate the model on a test set to determine its accuracy, F1 score, and other metrics after training on val set.\n",
    "\n",
    "**Description**: The evaluation section tests the model on unseen data to assess its generalization capabilities. Metrics like accuracy, F1 score, and balanced accuracy provide insights into model performance."
   ],
   "id": "93769069"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_path = r\"C:\\Users\\morit\\PycharmProjects\\AgePrediction\\model_weights\\model_epoch_78.pth\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = AgeNN(NUM_OF_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(model_path))    \n",
    "\n",
    "evaluate(val_loader, model, 0)"
   ],
   "id": "1b76df9649f4db7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Single Image Prediction with Pretrained Model\n",
    "\n",
    "This cell allows you to load a pretrained model from a specified path and make predictions on a single image. The image is preprocessed to match the model's input requirements, and the model outputs the predicted class label.\n",
    "\n",
    "### Code Overview\n",
    "\n",
    "- **Model Path Input**: Specify the path to the trained model file.\n",
    "- **Image Path Input**: Specify the path to the image file you want to classify.\n",
    "- **Class Names**: Provide a list of class names corresponding to the model’s output labels.\n"
   ],
   "id": "e523854aa7c83ab1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def predict_image(model_path, image_path):\n",
    "    model = AgeNN(NUM_OF_CLASSES)\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0) # Add Batch dim\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = f\"{predicted.item() * 10}-{predicted.item() * 10 + 10}\"\n",
    "\n",
    "    print(f'Predicted class: {predicted_class}')\n",
    "\n",
    "model_path = r\"C:\\Users\\morit\\PycharmProjects\\AgePrediction\\model_weights\\model_epoch_78.pth\"\n",
    "image_path = r\"C:\\Users\\morit\\Pictures\\BNMW8637.JPG\"\n",
    "\n",
    "\n",
    "# Run prediction\n",
    "predict_image(model_path, image_path)"
   ],
   "id": "5bf6c78ddae65699",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
