{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:34.341024Z",
     "start_time": "2024-11-06T06:46:21.104881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def imshow(image):\n",
    "    mean=torch.tensor([0.485, 0.456, 0.406])\n",
    "    std=torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    #normalize = transforms.Normalize(mean.tolist(), std.) \n",
    "\n",
    "    unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())\n",
    "    img_unn = unnormalize(image)\n",
    "    plt.imshow(img_unn.permute(1, 2, 0))\n",
    "    plt.show()"
   ],
   "id": "919c72e2ddce27a9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h1> Hyperparamters </h1>\n",
    "<h2> We will use the following hyperparameters for training the model:\n",
    "- Batch size: 512\n",
    "- Learning rate: 0.01\n",
    "- Number of epochs: 1000 </h2>\n",
    "<h3> We don’t have data for certain ages (e.g no image of a 94 year old person), so we can group ages into ranges (like 90–95, 95–100) instead of predicting each specific age. \n",
    "This is called class binning. By using age ranges, the model can handle missing data more effectively and make more accurate predictions, even with a smaller dataset.</h4>"
   ],
   "id": "d0604fbba59f9b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:34.373022Z",
     "start_time": "2024-11-06T06:46:34.354023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "SIZE_OF_BIN = 10\n",
    "NUM_OF_CLASSES = math.ceil(116 / SIZE_OF_BIN)\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1000"
   ],
   "id": "5b058e88b556611d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:42.188808Z",
     "start_time": "2024-11-06T06:46:34.384023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "# coutainer of classes\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_path):\n",
    "        self.image_files = [os.path.join(images_path, f) for f in os.listdir(images_path) \n",
    "                            if os.path.isfile(os.path.join(images_path, f)) and f.lower().endswith('.jpg')]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize([256], transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.CenterCrop([224]),\n",
    "            \n",
    "            # Subtle augmentations because a person normally e.g does not stand on upside down\n",
    "            transforms.RandomHorizontalFlip(p=0.2),       # Small chance of flipping\n",
    "            transforms.RandomRotation(degrees=5),         # Small rotation range\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),  # Subtle color jitter\n",
    "            \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_files[idx]).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        age = self.image_files[idx].split(\"\\\\\")[-1].split('_')[0]\n",
    "        return image, int(age) // SIZE_OF_BIN \n",
    "\n",
    "\n",
    "dataset = CustomDataset(r\"C:\\Users\\morit\\Downloads\\UTKface_inthewild-20241024T082001Z-001\\UTKface_inthewild\")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for images, labels in dataloader:\n",
    "    for i, labels in enumerate(labels):\n",
    "        \n",
    "        print(f\"{labels*SIZE_OF_BIN}-{labels*SIZE_OF_BIN + SIZE_OF_BIN}:\")\n",
    "    break\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "100-110:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n",
      "10-20:\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "Due to the large imbalance of the dataset, we need to calculate the class weights to ensure that the model does not overfit to the majority class.\n",
    " \n",
    "We will use the inverse frequency of each class as the class weight. This will help the model to pay more attention to the minority classes."
   ],
   "id": "30630d077010ecb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h1> Calculate Class Weights </h1>\n",
    "Since the calculation of class takes a long time, we will use the hardcoded output of the calculation."
   ],
   "id": "6588c434c753570b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:42.437808Z",
     "start_time": "2024-11-06T06:46:42.424810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import tensor\n",
    "class_weights_tensor = tensor([0.1378, 0.0637, 0.3042, 0.1891, 0.0946, 0.0966, 0.0550, 0.0298, 0.0220,\n",
    "        0.0058, 0.0007, 0.0006], dtype=torch.float)"
   ],
   "id": "9748bbcf8c9f8119",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:42.484810Z",
     "start_time": "2024-11-06T06:46:42.481808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# from collections import defaultdict\n",
    "# \n",
    "# # Step 1: Count occurrences of each class\n",
    "# class_counts = defaultdict(int)\n",
    "# \n",
    "# for _, labels in train_loader:\n",
    "#     for label in labels.numpy():\n",
    "#             \n",
    "#         class_counts[label] += 1\n",
    "# \n",
    "# # Step 2: Calculate class weights\n",
    "# total_samples = sum(class_counts.values())\n",
    "# \n",
    "# # Calculate weights: inverse frequency\n",
    "# class_weights = {cls: count/ total_samples for cls, count in class_counts.items()}\n",
    "# # Convert t a tensor for PyTorch\n",
    "# class_weights_tensor = torch.tensor([class_weights[i] for i in range(NUM_OF_CLASSES)], dtype=torch.float)\n",
    "# \n",
    "# print(\"Class weights:\", class_weights_tensor)\n"
   ],
   "id": "b17c8369204ee0e7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:42.545808Z",
     "start_time": "2024-11-06T06:46:42.527808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# \n",
    "# all_labels = []\n",
    "# \n",
    "# for _, labels in dataloader:\n",
    "#     all_labels.extend(labels.numpy())  \n",
    "# \n",
    "# all_labels = np.array(all_labels)\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(all_labels, bins=range(int(all_labels.min()), int(all_labels.max()) + 2), edgecolor='black', alpha=0.7)\n",
    "# plt.title('Age Distribution in Dataset')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.show()"
   ],
   "id": "cc55184d4babde6f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1> Model </h1>",
   "id": "532566d0e8fbaa56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:43.414808Z",
     "start_time": "2024-11-06T06:46:42.563809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class highLevelNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(highLevelNN, self).__init__()\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.CNN(x)\n",
    "\n",
    "\n",
    "class lowLevelNN(nn.Module):\n",
    "    def __init__(self, num_out):\n",
    "        super(lowLevelNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc4 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc5 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc6 = nn.Linear(in_features=64, out_features=num_out)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=6, stride=3, padding=1)\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=6, stride=3, padding=1)\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc6(x)\n",
    "\n",
    "\n",
    "class AgeNN(nn.Module):\n",
    "    def __init__(self, num_age):\n",
    "        super(AgeNN, self).__init__()\n",
    "        self.CNN = highLevelNN()\n",
    "        self.ageNN = lowLevelNN(num_out=num_age)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.CNN(x)\n",
    "        return self.ageNN(x)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchsummary import summary\n",
    "    print('Testing out Multi-Label NN')\n",
    "    mlNN = AgeNN(NUM_OF_CLASSES).to(device)\n",
    "    \n",
    "    summary(mlNN, input_size=(3, 224, 224))\n"
   ],
   "id": "e911e0e6d1e758e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing out Multi-Label NN\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]             896\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "              ReLU-3         [-1, 32, 224, 224]               0\n",
      "            Conv2d-4         [-1, 32, 224, 224]           9,248\n",
      "       BatchNorm2d-5         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-6         [-1, 32, 112, 112]               0\n",
      "              ReLU-7         [-1, 32, 112, 112]               0\n",
      "           Dropout-8         [-1, 32, 112, 112]               0\n",
      "            Conv2d-9         [-1, 64, 112, 112]          18,496\n",
      "      BatchNorm2d-10         [-1, 64, 112, 112]             128\n",
      "             ReLU-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "        MaxPool2d-14           [-1, 64, 56, 56]               0\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "          Dropout-16           [-1, 64, 56, 56]               0\n",
      "           Conv2d-17          [-1, 128, 56, 56]          73,856\n",
      "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
      "             ReLU-19          [-1, 128, 56, 56]               0\n",
      "           Conv2d-20          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-21          [-1, 128, 56, 56]             256\n",
      "        MaxPool2d-22          [-1, 128, 28, 28]               0\n",
      "             ReLU-23          [-1, 128, 28, 28]               0\n",
      "          Dropout-24          [-1, 128, 28, 28]               0\n",
      "      highLevelNN-25          [-1, 128, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 14, 14]         262,272\n",
      "      BatchNorm2d-27          [-1, 128, 14, 14]             256\n",
      "           Conv2d-28            [-1, 256, 4, 4]         295,168\n",
      "      BatchNorm2d-29            [-1, 256, 4, 4]             512\n",
      "           Linear-30                  [-1, 128]          32,896\n",
      "          Dropout-31                  [-1, 128]               0\n",
      "           Linear-32                   [-1, 64]           8,256\n",
      "          Dropout-33                   [-1, 64]               0\n",
      "           Linear-34                   [-1, 12]             780\n",
      "       lowLevelNN-35                   [-1, 12]               0\n",
      "================================================================\n",
      "Total params: 888,044\n",
      "Trainable params: 888,044\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 124.48\n",
      "Params size (MB): 3.39\n",
      "Estimated Total Size (MB): 128.44\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T06:46:47.110808Z",
     "start_time": "2024-11-06T06:46:43.447809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train(trainloader, testloader, model, opt, scheduler, num_epoch, save_path):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    age_loss = nn.CrossEntropyLoss()\n",
    "    print(\"1\")\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "\n",
    "        loop = tqdm(enumerate(trainloader), total=len(trainloader), leave=False)\n",
    "        age_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "\n",
    "        for _, (X, y) in loop:\n",
    "\n",
    "            age = y.to(device).long()\n",
    "            X = X.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                pred = model(X)\n",
    "                loss = age_loss(pred, age)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            age_correct += (pred.argmax(1) == age).type(torch.float).sum().item()\n",
    "            total += age.size(0)\n",
    "\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{num_epoch}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        age_acc = age_correct / total\n",
    "        print(f'Epoch: {epoch+1}/{num_epoch}, Age Accuracy: {age_acc * 100:.2f}%')\n",
    "\n",
    "        torch.save(model.state_dict(), f\"{save_path}/model_epoch_{epoch+1}.pth\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            evaluate(testloader, model, epoch + 1)\n",
    "            \n",
    "def evaluate(testloader, model, epoch):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for X_test, y_test in testloader:\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device).long()\n",
    "        test_pred = model(X_test)\n",
    "        \n",
    "        test_correct += (test_pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
    "        test_total += y_test.size(0)\n",
    "        \n",
    "        all_preds.extend(test_pred.argmax(1).cpu().numpy())\n",
    "        all_labels.extend(y_test.cpu().numpy())\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f'Test Accuracy after Epoch {epoch}: {test_acc * 100:.2f}%')\n",
    "    print(f'Test F1 Score after Epoch {epoch}: {f1 * 100:.2f}%')\n",
    "    print(f'Test Balanced Accuracy after Epoch {epoch}: {balanced_acc * 100:.2f}%\\n')"
   ],
   "id": "e5a585add2fe4496",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T14:03:00.232890Z",
     "start_time": "2024-11-06T06:46:47.146812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# Decrease the learning rate by 0.1 every 10 epochs\n",
    "import os   \n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "model = AgeNN(NUM_OF_CLASSES)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "# Train the model\n",
    "train(train_loader, test_loader, model, optimizer,scheduler, EPOCHS, \"model_weights\")"
   ],
   "id": "6eb9b2e3cc257fa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000, Age Accuracy: 26.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/1000, Age Accuracy: 30.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/1000, Age Accuracy: 33.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/1000, Age Accuracy: 36.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/1000, Age Accuracy: 38.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/1000, Age Accuracy: 40.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/1000, Age Accuracy: 42.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/1000, Age Accuracy: 43.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/1000, Age Accuracy: 44.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/1000, Age Accuracy: 44.86%\n",
      "Test Accuracy after Epoch 10: 44.73%\n",
      "Test F1 Score after Epoch 10: 39.02%\n",
      "Test Balanced Accuracy after Epoch 10: 18.97%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/1000, Age Accuracy: 46.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/1000, Age Accuracy: 46.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/1000, Age Accuracy: 46.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/1000, Age Accuracy: 47.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/1000, Age Accuracy: 47.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/1000, Age Accuracy: 47.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/1000, Age Accuracy: 48.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/1000, Age Accuracy: 47.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/1000, Age Accuracy: 47.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/1000, Age Accuracy: 48.26%\n",
      "Test Accuracy after Epoch 20: 49.17%\n",
      "Test F1 Score after Epoch 20: 41.41%\n",
      "Test Balanced Accuracy after Epoch 20: 23.45%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/1000, Age Accuracy: 48.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/1000, Age Accuracy: 48.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/1000, Age Accuracy: 48.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/1000, Age Accuracy: 48.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/1000, Age Accuracy: 47.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/1000, Age Accuracy: 48.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/1000, Age Accuracy: 47.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/1000, Age Accuracy: 48.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/1000, Age Accuracy: 48.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/1000, Age Accuracy: 48.28%\n",
      "Test Accuracy after Epoch 30: 49.42%\n",
      "Test F1 Score after Epoch 30: 41.83%\n",
      "Test Balanced Accuracy after Epoch 30: 23.39%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/1000, Age Accuracy: 48.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/1000, Age Accuracy: 48.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/1000, Age Accuracy: 48.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/1000, Age Accuracy: 48.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/1000, Age Accuracy: 48.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/1000, Age Accuracy: 48.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/1000, Age Accuracy: 48.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/1000, Age Accuracy: 48.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/1000, Age Accuracy: 48.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/1000, Age Accuracy: 48.44%\n",
      "Test Accuracy after Epoch 40: 50.17%\n",
      "Test F1 Score after Epoch 40: 42.70%\n",
      "Test Balanced Accuracy after Epoch 40: 23.87%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/1000, Age Accuracy: 48.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/1000, Age Accuracy: 48.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/1000, Age Accuracy: 48.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/1000, Age Accuracy: 48.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/1000, Age Accuracy: 48.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/1000, Age Accuracy: 48.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/1000, Age Accuracy: 48.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/1000, Age Accuracy: 48.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/1000, Age Accuracy: 48.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/1000, Age Accuracy: 48.95%\n",
      "Test Accuracy after Epoch 50: 49.17%\n",
      "Test F1 Score after Epoch 50: 41.43%\n",
      "Test Balanced Accuracy after Epoch 50: 22.80%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/1000, Age Accuracy: 48.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/1000, Age Accuracy: 48.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/1000, Age Accuracy: 48.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/1000, Age Accuracy: 48.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/1000, Age Accuracy: 48.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/1000, Age Accuracy: 48.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/1000, Age Accuracy: 48.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/1000, Age Accuracy: 48.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/1000, Age Accuracy: 48.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/1000, Age Accuracy: 48.82%\n",
      "Test Accuracy after Epoch 60: 49.34%\n",
      "Test F1 Score after Epoch 60: 41.86%\n",
      "Test Balanced Accuracy after Epoch 60: 23.10%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/1000, Age Accuracy: 48.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/1000, Age Accuracy: 48.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/1000, Age Accuracy: 48.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/1000, Age Accuracy: 48.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/1000, Age Accuracy: 48.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/1000, Age Accuracy: 48.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/1000, Age Accuracy: 48.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/1000, Age Accuracy: 48.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/1000, Age Accuracy: 48.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/1000, Age Accuracy: 48.43%\n",
      "Test Accuracy after Epoch 70: 49.59%\n",
      "Test F1 Score after Epoch 70: 42.01%\n",
      "Test Balanced Accuracy after Epoch 70: 23.54%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/151 [00:00<?, ?it/s]C:\\Users\\morit\\AppData\\Local\\Temp\\ipykernel_13072\\2973268851.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/1000, Age Accuracy: 48.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/1000, Age Accuracy: 48.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/1000, Age Accuracy: 48.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/1000, Age Accuracy: 48.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/1000, Age Accuracy: 48.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/1000, Age Accuracy: 48.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/1000, Age Accuracy: 48.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/1000, Age Accuracy: 48.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m StepLR(optimizer, step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_weights\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 22\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(trainloader, testloader, model, opt, scheduler, num_epoch, save_path)\u001B[0m\n\u001B[0;32m     18\u001B[0m age_correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     19\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, (X, y) \u001B[38;5;129;01min\u001B[39;00m loop:\n\u001B[0;32m     24\u001B[0m     age \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mlong()\n\u001B[0;32m     25\u001B[0m     X \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\tqdm\\std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "Cell \u001B[1;32mIn[3], line 30\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m---> 30\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_files\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRGB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n\u001B[0;32m     32\u001B[0m     age \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_files[idx]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\PIL\\Image.py:921\u001B[0m, in \u001B[0;36mImage.convert\u001B[1;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[0;32m    873\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\n\u001B[0;32m    874\u001B[0m     \u001B[38;5;28mself\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, matrix\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dither\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, palette\u001B[38;5;241m=\u001B[39mPalette\u001B[38;5;241m.\u001B[39mWEB, colors\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m\n\u001B[0;32m    875\u001B[0m ):\n\u001B[0;32m    876\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;124;03m    method translates pixels through the palette.  If mode is\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001B[39;00m\n\u001B[0;32m    919\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 921\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    923\u001B[0m     has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    925\u001B[0m         \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\detectron2_yml_test\\lib\\site-packages\\PIL\\ImageFile.py:260\u001B[0m, in \u001B[0;36mImageFile.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[0;32m    255\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage file is truncated \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    256\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(b)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m bytes not processed)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    257\u001B[0m         )\n\u001B[0;32m    259\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[1;32m--> 260\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    262\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
